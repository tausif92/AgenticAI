{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45615084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(name=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd3d216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a subset of artificial intelligence that involves the development of algorithms and models that enable computers to learn from and make predictions or decisions based on data without being explicitly programmed. In simple terms, machine learning is the process of training a computer or machine to improve its performance on a task by learning from data and experience rather than through explicit programming.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 12, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAbPfSWKak7fvMXD1R5JXr8k6QjB6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8ef2e722-df1d-4a99-8cb8-d649c0eead68-0', usage_metadata={'input_tokens': 12, 'output_tokens': 69, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcfb8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "from typing_extensions import Literal, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174d4819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MyDrive\\SelfStudyCode\\AI\\Krish\\AgenticAI\\venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1906: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class Section(BaseModel):\n",
    "    name: str = Field(description=\"Name of this section of the report\")\n",
    "    description: str = Field(description=\"Brief overview of the main topic and concepts of the section\")\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(description=\"Sections of the report\")\n",
    "\n",
    "planner = llm.with_structured_output(Sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ee977",
   "metadata": {},
   "source": [
    "### Creating the workers dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535fc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    sections: list[Section]\n",
    "    completed_sections: Annotated[list, operator.add]\n",
    "    final_report: str\n",
    "\n",
    "# Worker state\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    completed_sections: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f8ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes\n",
    "def orchestrator(state: State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "\n",
    "    # Generate queries\n",
    "    report_secitons = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Generate a plan for the report\"),\n",
    "            HumanMessage(content=f\"Here is the report for the topic: {state['topic']}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Report Sections: \", report_secitons)\n",
    "\n",
    "    return {\"sections\": report_secitons.sections}\n",
    "\n",
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "    # Generate section\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Write a report section following the provided name and description. Include no preamble for each section\"),\n",
    "            HumanMessage(content=f\"Here is the section name: {state['section'].name} and description: {state['section'].description}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Wriet the updated section to completed sections\n",
    "    return {\"completed_sections\": [section.content]}\n",
    "\n",
    "# Conditional edge function to create llm_call workers that each write a section of the report\n",
    "def assign_worker(state: State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "\n",
    "    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]\n",
    "\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "\n",
    "    return {\"final_report\": completed_report_sections}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1f59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45453f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc53fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
